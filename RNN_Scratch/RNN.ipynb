{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659a3be6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e0db10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>rain</th>\n",
       "      <th>tmax_tomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01</th>\n",
       "      <td>60.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-02</th>\n",
       "      <td>52.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-03</th>\n",
       "      <td>52.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-04</th>\n",
       "      <td>53.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-05</th>\n",
       "      <td>52.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-22</th>\n",
       "      <td>62.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-23</th>\n",
       "      <td>67.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-24</th>\n",
       "      <td>66.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-25</th>\n",
       "      <td>70.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-26</th>\n",
       "      <td>62.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13509 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tmax  tmin  rain  tmax_tomorrow\n",
       "1970-01-01  60.0  35.0   0.0           52.0\n",
       "1970-01-02  52.0  39.0   0.0           52.0\n",
       "1970-01-03  52.0  35.0   0.0           53.0\n",
       "1970-01-04  53.0  36.0   0.0           52.0\n",
       "1970-01-05  52.0  35.0   0.0           50.0\n",
       "...          ...   ...   ...            ...\n",
       "2022-11-22  62.0  35.0   0.0           67.0\n",
       "2022-11-23  67.0  38.0   0.0           66.0\n",
       "2022-11-24  66.0  41.0   0.0           70.0\n",
       "2022-11-25  70.0  39.0   0.0           62.0\n",
       "2022-11-26  62.0  41.0   0.0           64.0\n",
       "\n",
       "[13509 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(\"clean_weather.csv\",index_col = 0)\n",
    "data = data.ffill()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db862d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1970-01-01    60.0\n",
       "1970-01-02    52.0\n",
       "1970-01-03    52.0\n",
       "1970-01-04    53.0\n",
       "1970-01-05    52.0\n",
       "1970-01-06    50.0\n",
       "1970-01-07    52.0\n",
       "1970-01-08    56.0\n",
       "1970-01-09    54.0\n",
       "1970-01-10    57.0\n",
       "Name: tmax, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"tmax\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d6ad2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[60., 52., 52., 53., 52., 50., 52., 56., 54., 57.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"tmax\"].head(10).to_numpy()[np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bcb5612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[60.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"tmax\"].head(1).to_numpy()[np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ad676c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([66., 70., 62.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "# Set a random seed so the random numbers are the same every time\n",
    "i_weight = np.random.rand(1,2)\n",
    "h_weight = np.random.rand(2,2)\n",
    "o_weight = np.random.rand(2,1)\n",
    "\n",
    "temps = data[\"tmax\"].tail(3).to_numpy()\n",
    "temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a41ed0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = temps[0].reshape(1,1)\n",
    "x1 = temps[1].reshape(1,1)\n",
    "x2 = temps[2].reshape(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3958acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[66.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2117c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[36.22169126, 47.20249818]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xi_0 = x0 @ i_weight\n",
    "xi_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e12f7502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[36.22169126, 47.20249818]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xh_0 = np.maximum(0, xi_0) # relu activation funcitno\n",
    "xh_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab6efa44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[57.94406231]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is no previous time step, so there is no hidden state\n",
    "# apply relu over the input to get the hidden state for time step 0 xh_0\n",
    "xo_0 = xh_0 @ o_weight\n",
    "xo_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01297b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[124.54916092]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xi_1 = x1 @ i_weight\n",
    "\n",
    "xh = xh_0 @ h_weight\n",
    "\n",
    "xh_1 = np.maximum(0, xh + xi_1)\n",
    "\n",
    "xo_1 = xh_1 @ o_weight\n",
    "\n",
    "xo_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b1551b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[190.94853131]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We feed the input in the same way as the previous time step\n",
    "xi_2 = x2 @ i_weight\n",
    "\n",
    "# This time, we do have a previous time step, so we calculate xh\n",
    "# This is multiplying the previous hidden state xh_1 by the hidden weights\n",
    "xh = xh_1 @ h_weight\n",
    "\n",
    "# We add the previous hidden state (times h_weight) to the input at time step 2\n",
    "xh_2 = np.maximum(0, xh + xi_2)\n",
    "\n",
    "# We again find the output by multiplying xh_1 by the output weight\n",
    "xo_2 = xh_2 @ o_weight\n",
    "\n",
    "xo_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94a515ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperbolic tan\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "temps = np.arange(-10, 10, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9e0980c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20bddb8b850>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(temps, np.tanh(temps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ef4e9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{\\left(- e^{x} + e^{- x}\\right) \\left(e^{x} - e^{- x}\\right)}{\\left(e^{x} + e^{- x}\\right)^{2}} + 1$"
      ],
      "text/plain": [
       "(-exp(x) + exp(-x))*(exp(x) - exp(-x))/(exp(x) + exp(-x))**2 + 1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy import diff, symbols, exp\n",
    "\n",
    "x = symbols(\"x\")\n",
    "sympy_tanh = (exp(x) - exp(-x)) / (exp(x) + exp(-x))\n",
    "diff(sympy_tanh, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3cafd430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20be215c2b0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAAsTAAALEwEAmpwYAAAirUlEQVR4nO3daXRkZ33n8e+/SvvWUmvtRb2rDR22tjvGxiZAMMaQwY5nQrBnCDAw8TCMZ8gJSY5z4PgwzptJmGQySZwQkzAEkokxJJg+pInBxGHzgtu4vXQ33a3eLLXUpX1XaatnXtQtuVpdkkpSVd1bVb/POTqquvfWrb9ulX569Nzn1mPOOUREJP+F/C5AREQyQ4EuIlIgFOgiIgVCgS4iUiAU6CIiBaLEryduampyu3bt8uvpRUTy0nPPPTfgnGtOtc63QN+1axdHjx716+lFRPKSmV1cbp26XERECoQCXUSkQCjQRUQKhAJdRKRAKNBFRArEqoFuZl80sz4ze3mZ9WZmf2JmnWb2opldm/kyRURkNem00L8E3LbC+vcAHd7XPcBfbLwsERFZq1UD3Tn3A2BohU3uAL7s4p4G6s1sS6YKFMm1rqEpDr/Q43cZImuWiQuLtgFdSfe7vWW9Szc0s3uIt+LZsWNHBp5aJLNGp+f4tb9+hguDU0zNzHPX9XqfSv7I6UlR59xDzrlDzrlDzc0pr1wV8Y1zjt/+2gt0D0/zum113H/4OC9fGvW7LJG0ZSLQLwHtSfe3e8tE8sr5gUm+cyLCJ9/ZwZc/+mYqSkJ86ckLfpclkrZMBPph4EPeaJcbgFHn3FXdLSJB9+POAQDe98atbK4u4+aOJn7cOYCmaZR8kc6wxb8HngKuMbNuM/uYmX3czD7ubXIEOAd0Al8APpG1akWy6EedA2xvqGRnYxUAN+9rpnc0ytn+SZ8rE0nPqidFnXN3r7LeAf81YxWJ+GAh5njy7CC/9PotmBkAN+9rAuIt930tNX6WJ5IWXSkqArx0aZTx6Dw3eSEOsKOxih2bq/iR1xUjEnQKdBFe7T9/y97GK5bftK+Jp88OMr8Q86MskTVRoIsAL3WPsqepmsaa8iuWX7ezgfGZeS4OTflUmUj6FOgiwOm+cTpar+4n3+8tOxMZz3VJImumQJeiF51b4MLAJPtba69alzgZeuryRK7LElkzBboUvXP9k8QcdKQI9KqyEto3V3K6Ty10CT4FuhS9M15YX5Mi0BPL1eUi+UCBLkXvdGSckpCxu6k65fqO1lrOD0wyp5EuEnAKdCl6pyMT7Gqqpqwk9a/D/tYa5hYcFwZ0xagEmwJdit6ZyPjiaJZUOlriXTGnIzoxKsGmQJeiFp1b4OLQ1GJop7KvpYaQwSn1o0vAKdClqF0cnMI52NOcuv8coKI0zLaGSnW5SOAp0KWodXlXgO7YXLXidu0NVXQN62pRCTYFuhS1REi3pxPoQ9O5KElk3RToUtS6hqapLA3TWF224nbtmysZmJhhenYhR5WJrJ0CXYraK0NT7NhctfgZ6MtJtODV7SJBpkCXotY9PEX75spVt1sMdH3qogSYAl2KlnOOrqEptjes3H8O8T50UKBLsCnQpWgNT80xObuw6ggXgKaaMipLw3QN68SoBJcCXYrWK0PpjXABMDPaN1cuPkYkiBToUrS6FgN99T50SAxdVKBLcCnQpWgtjkFPow8d4i357uFpnHPZLEtk3RToUrS6hqbZXF1GdXlJWtu3b65iYmae4am5LFcmsj4KdClaPSPTbKtPr7sFYFt9xeLjRIJIgS5Fq3d0mi2bKtLefsumSu9x0WyVJLIhCnQpWr2j0TUGenzby6NqoUswKdClKE3MzDMenWfLGrpcmmrKKQ0bPWqhS0Ap0KUo9Xr94GtpoYdCRmtdxeJjRYJGgS5FKdEPnugXT9eWTRXqQ5fAUqBLUeodXXsLPb59pQJdAkuBLkWpdzSKGbTWrTXQK7g8GiUW08VFEjxpBbqZ3WZmp8ys08zuS7F+h5k9YWbPm9mLZvbezJcqkjm9I1GaasopK1lbm2bLpgpmF2IMTc1mqTKR9Vv13WxmYeBB4D3AAeBuMzuwZLPPAI845w4CdwF/nulCRTKpZ3SarWvsbgEWR8X0jqjbRYInnebJ9UCnc+6cc24WeBi4Y8k2Dqjzbm8CejJXokjmXR6N0raeQPce06ux6BJA6QT6NqAr6X63tyzZZ4EPmlk3cAT4b6l2ZGb3mNlRMzva39+/jnJFMiN+UdHaRriArhaVYMvUSdG7gS8557YD7wW+YmZX7ds595Bz7pBz7lBzc3OGnlpkbcaic0zMzLO1fu0t9MbqMu/iIrXQJXjSCfRLQHvS/e3esmQfAx4BcM49BVQATZkoUCTTLnut67Z1tNBDIaPNG+kiEjTpBPqzQIeZ7TazMuInPQ8v2eYV4J0AZvZa4oGuPhUJpMiYF+hrHLKY0FZXsbgPkSBZNdCdc/PAvcBjwEnio1mOm9kDZna7t9mngF83sxeAvwc+4jQLgARUZGwGgNa68nU9vqWuYnEfIkGS1if7O+eOED/Zmbzs/qTbJ4CbMluaSHYkWtcttetvoT/xsz6cc5hZJksT2RBdKSpFp28sSl1FCZVl4XU9vrWunKnZBcZn5jNcmcjGKNCl6ETGZtZ8yX+yxGP71I8uAaNAl6ITGY9mJNAvj6ofXYJFgS5Fp29shpZ1nhCFVwNdI10kaBToUlRiMUdkbKMt9Pgfg8sKdAkYBboUlaGpWeZjbt1j0AGqykqorShRH7oEjgJdikqim2S9Y9AT2uoq1EKXwFGgS1Hp8y4IatlACx3i/ei6uEiCRoEuReXVFvrGA11dLhI0CnQpKolWdXPNxrpcWuvK6Ruf0VR0EigKdCkqkfEojdVla556bqm2TRXMxxyDk5qKToJDgS5FpW8suuH+c3j1c2A0Fl2CRIEuRSV+2f/Gulvg1VEyCnQJEgW6FJXLY1Fa1/kpi8kS85Fq6KIEiQJdisb8QoyBiRla1zE59FJNNeWYoaGLEigKdCkaAxOzOLfxi4oASsMhmmrKiWgqOgkQBboUjcUx6BnocoH4H4bIuAJdgkOBLkUjUxcVJbTpalEJGAW6FI3I+MbmEl2qRZNFS8Ao0KVo9I1FCRk0bvAq0YS2ugqGJmeZmV/IyP5ENkqBLkUjMhalubaccCgzEzsnWvp96naRgFCgS9HY6FyiSyWuOO3TiVEJCAW6FI3IWHTxkv1MaNPcohIwCnQpGpGxKG2bMtN/DppbVIJHgS5FYWZ+geGpuYyNQQdoqCqlLBxSoEtgKNClKCROXGayD93MaKkrV6BLYCjQpSgkTlw2Z2gMeoIuLpIgUaBLUUicuGzLYAsdEnOLqoUuwaBAl6KQ+JhbBboUMgW6FIXIWJSykhD1VaUZ3W9rXTmTswuMR+cyul+R9Ugr0M3sNjM7ZWadZnbfMtv8qpmdMLPjZvb/MlumyMZcHo3SVleBWWauEk1ITHShfnQJgpLVNjCzMPAg8C6gG3jWzA47504kbdMB/C5wk3Nu2MxaslWwyHpExqIZ726BK+cW3ddSk/H9i6xFOi3064FO59w559ws8DBwx5Jtfh140Dk3DOCc68tsmSIbExmL0pLhES6guUUlWNIJ9G1AV9L9bm9Zsv3AfjP7sZk9bWa3pdqRmd1jZkfN7Gh/f//6KhZZI+ccl7PUQk+Ma9fcohIEmTopWgJ0AG8H7ga+YGb1Szdyzj3knDvknDvU3NycoacWWdnY9DzRudhif3cmVZeXUFteok9clEBIJ9AvAe1J97d7y5J1A4edc3POufPAaeIBL+K7yxmeqWip1k0auijBkE6gPwt0mNluMysD7gIOL9nmUeKtc8ysiXgXzLnMlSmyfomwzUYLHeL96OpykSBYNdCdc/PAvcBjwEngEefccTN7wMxu9zZ7DBg0sxPAE8BvO+cGs1W0yFpk66KihNa6CnW5SCCsOmwRwDl3BDiyZNn9Sbcd8Jvel0igREa9z3GpzfwoF3j1atFYzBHK0GxIIuuhK0Wl4F0ei9JQVUpFaTgr+2+rq2A+5hiams3K/kXSpUCXghcZi2bthCi8Ohb98qj60cVfCnQpeJGxmaydEAXNLSrBoUCXgpeti4oSNLeoBIUCXQra3EKMgYmZxVZ0NjTXlmOmy//Ffwp0KWj94zM4l70hiwCl4RCN1ZqKTvynQJeCtjgGfVN2hiwmtGpuUQkABboUtL4sX/afoLlFJQgU6FLQEkMJs9nlAvGRLmqhi98U6FLQLo/NUBo2NleXZfV52uoqGJycZXY+ltXnEVmJAl0KWmQsSktt5qeeWypxcZHGooufFOhS0C6PRrN6UVFCq+YWlQBQoEtBi4xn96KihNakuUVF/KJAl4IWGc3u57gkaG5RCQIFuhSs8egck7MLWR+DDrC5uozSsGmiC/GVAl0KViRHY9ABzIyWWk10If5SoEvBSnxYVi4CHeJT3OkjdMVPCnQpWD2j0wBs3VSZk+fbsqmCXu85RfygQJeC1TMyjRm05qAPHWBrfSU9o1HiMzKK5J4CXQpW70iUpppyykuyM/XcUls3VTA7H2NwUlPRiT8U6FKwekan2Vqfm+4WgC3ec/WOqB9d/KFAl4LVMzLNtvrcnBAF2OYF+qUR9aOLPxToUpCcc/SMRNmSoxOiwOJ/Az0KdPGJAl0K0sjUHNNzCzntcmmoKqW8JKSRLuIbBboUpFeHLOauy8XM2FZfSY/60MUnCnQpSIlQzWULHWBLfcXiHxORXFOgS0FK9GNvyeFJUYhfxKQ+dPGLAl0KUs/oNGXhEE3VubmoKGFrfSV94zPMLWjmIsk9BboUpJ6R+MQWoVB2Zypaamt9Bc6hz3QRXyjQpSD1jEyzJYcnRBM0dFH8pECXgnRpeJrtDVU5f15dXCR+SivQzew2MztlZp1mdt8K2/07M3NmdihzJYqszcz8ApHxKNsbcjvCBV5toXcNKdAl91YNdDMLAw8C7wEOAHeb2YEU29UCnwSeyXSRImvRMxLFOWjfnPsWekVpmNa6crqGp3L+3CLptNCvBzqdc+ecc7PAw8AdKbb7PeD3AZ0NEl91DcXDtN2HFnr8eavoVqCLD9IJ9G1AV9L9bm/ZIjO7Fmh3zv3TSjsys3vM7KiZHe3v719zsSLpSLSOt/vQQgfY3lCpLhfxxYZPippZCPgj4FOrbeuce8g5d8g5d6i5uXmjTy2SUvfwNCUhoy1HU88t1b65it7RaY1Fl5xLJ9AvAe1J97d7yxJqgdcB/2pmF4AbgMM6MSp+6RqaYmt9JeEcj0FPaG+oIqax6OKDdAL9WaDDzHabWRlwF3A4sdI5N+qca3LO7XLO7QKeBm53zh3NSsUiq+genqZ9sz/958Di6JpEX75Irqwa6M65eeBe4DHgJPCIc+64mT1gZrdnu0CRteoenqLdhzHoCYnRNRrpIrlWks5GzrkjwJEly+5fZtu3b7wskfWZnl1gYGLWlzHoCW2bKghZ/D8FkVzSlaJSUBLDBf0Yg55QGg6xZVOlulwk5xToUlAWhyz62OUC0L65ki610CXHFOhSUC4OxgN9h48t9MTzJ2oRyRUFuhSUi4NT1JSX0FRT5msdu5qqGZiYYWJm3tc6pLgo0KWgnB+YZGdjFWb+jEFP2NVYDcCFgUlf65DiokCXgnJhcJJdTdV+l/FqoA8q0CV3FOhSMOYWYnQPT7Or0d/+c4CdXg3qR5dcUqBLwegenmYh5hZbx36qLi+hpbac8+pykRxSoEvBSHRvBKHLBeLdLhfV5SI5pECXgpE4ARmEFjrArqYqzg+oy0VyR4EuBSMoQxYTNHRRck2BLgUjKEMWEzR0UXJNgS4FIyhDFhMSga4To5IrCnQpCNG5BbqGptjbXON3KYv2NFdjBmf7J/wuRYqEAl0Kwrn+SWIOOlqCE+gVpWHaG6o406dAl9xQoEtB6PRawR2twQl0gH0tNZxVoEuOKNClIHRGxgkZ7A5QHzrE/2M41z/JvCaMlhxQoEtBONM3wc7GaspLwn6XcoV9LTXMLsR4RZNdSA4o0KUgdPZNsC9A/ecJiZo61e0iOaBAl7w3txDj/MBkoE6IJiQCXSdGJRcU6JL3Lg5OMR9zgWyh11aU0lZXoROjkhMKdMl7nX3jAHS01PpcSWodrTWc9moUySYFuuS9n10exwz2tgRrhEvC/tZazkQmNNJFsk6BLnnvRM8Ye5qqqSor8buUlA5sqWNmPqbZiyTrFOiS9070jnFg6ya/y1jWga11ABzvGfO5Eil0CnTJa6PTc3QPT3NgS53fpSxrb3MNZeEQJ3oV6JJdCnTJaye9kEy0goOorCRER2sNJ9RClyxToEteS4Tka7cEc4RLwoEtdZzoGcM553cpUsAU6JLXTvSO0VRTTktthd+lrOjA1joGJ2fpH5/xuxQpYAp0yWsnesYC3d2SkOjjP65+dMmitALdzG4zs1Nm1mlm96VY/5tmdsLMXjSz75nZzsyXKnKl6NwCZ/rG+bk8CPTXbq3DDF7qHvW7FClgqwa6mYWBB4H3AAeAu83swJLNngcOOefeAHwd+INMFyqy1PGeUeYWHAfb6/0uZVV1FaXsa67hWNeI36VIAUunhX490OmcO+ecmwUeBu5I3sA594RzLvH5oE8D2zNbpsjVnn9lBIA37aj3tY50HdxRz/OvDOvEqGRNOoG+DehKut/tLVvOx4Bvp1phZveY2VEzO9rf359+lSIpPP/KCNsbKgN/QjTh4I4GhqfmuDioz0aX7MjoSVEz+yBwCPhcqvXOuYecc4ecc4eam5sz+dRShJ5/ZZiDOxr8LiNtB73/JJ7vGva3EClY6QT6JaA96f52b9kVzOwW4NPA7c45jc2SrLo8GqVnNJoX/ecJHS21VJeFF7uKRDItnUB/Fugws91mVgbcBRxO3sDMDgJ/STzM+zJfpsiVjnmt3IN50n8OEA4Zb2yv14lRyZpVA905Nw/cCzwGnAQecc4dN7MHzOx2b7PPATXA18zsmJkdXmZ3Ihnxk/PDlJeE8mIMerLrdjZwvGeMiZl5v0uRApTW5406544AR5Ysuz/p9i0ZrktkRU+dG+TQrobATQq9mhv3NPKn/9LJs+eHeMdrWvwuRwqMrhSVvDM0OcvJ3jFu3NPodylrdu3OBsrCIZ46N+h3KVKAFOiSd572wvDGvU0+V7J2FaVhrt1Zz5NnB/wuRQqQAl3yzlNnB6kqC/OG7cGd1GIlN+5p4njPGCNTs36XIgVGgS5558mzA1y/ezOl4fx8+75lXyPOwdPnhvwuRQpMfv5GSNHqHp7ibP8kN+Vhd0vCG7fXU10W5vundbW0ZJYCXfLK907GL3O45UCrz5WsX1lJiF/Y38y//CxCLKbPdZHMUaBLXnn8ZIS9zdXsbqr2u5QNueW1rUTGZni5Rx+nK5mjQJe8MR6d4+lzg9zy2vxtnSe84zUthAwePxHxuxQpIAp0yRs/OD3A3ILL6+6WhM3VZVy3s4HvntQnZUjmKNAlb/zTSz00VpdxbR59wuJKbj3QxsneMc71T/hdihQIBbrkhdHpOR4/2cf73riVcMj8Licj3vfGrZjBo8d6/C5FCoQCXfLCt1/qZXY+xp0HV5pbJb+0bargpr1NPPr8Jc1iJBmhQJe88I3nL7GnuTpvrw5dzi8f3MYrQ1P89BVNeiEbp0CXwLswMMkz54e4803bMCuM7paE217XRmVpmK8+27X6xiKrUKBL4H3pyQuUho0P/Hz76hvnmZryEu68dhvfPNbD0KQ+20U2RoEugTYenePrz3XzS6/fQktdfkwGvVYfecsuZuZjPPzsK36XInlOgS6B9rWj3UzMzPORm3b7XUrW7G+t5aZ9jXzlqYvMzsf8LkfymAJdAis6t8Dnv3+Wn9/VwJvyaDLo9fj1t+6hdzTK155TX7qsnwJdAusrT12kb3yGT916jd+lZN3b9jdz3c4G/vR7nUTnFvwuR/KUAl0CaSw6x198/yxv7Wjihjycam6tzIzfuvUaLo9F+cpTF/0uR/KUAl0C6XP/fIqRqVl+592v8buUnLlxbyNvv6aZP378NL2j036XI3lIgS6Bc6xrhL995iIfunEXry+wC4lW88Dtr2M+5vgfh0/4XYrkIQW6BMrEzDy/+dVjtNSW86lb9/tdTs7taKzik7d08M/HL/MPz3X7XY7kGQW6BIZzjs984yUuDE7yvz/wJmorSv0uyRf3vHUPb969mc88+jJnIuN+lyN5RIEugfHn/3qWR4/18Bu37OcteTxn6EaVhEP8yd0HqS4P87G/OUrfeNTvkiRPKNAlEP726Yt87rFT3HlwG/e+Y5/f5fiuta6CL3zoEP3jM3zki88yrI8FkDQo0MVXzjkefKKTzzz6Mr/4mhb+4FfeQKhAPu98ow7uaODzv3Ydnf0TvP8vn6JnRCNfZGUKdPHNeHSO//7wMT732Cl++U1b+fwHr6M0rLdksrftb+bLH72eyGiU2//sR/zwTL/fJUmA6bdHfPG9kxFu++Mf8k8v9vDb776GP/rVN1FWordjKjfsaeQfP/EWGqrK+NAXf8Knv/ESo1NzfpclAVTidwFSPGIxx5NnB/mzJ87w9LkhOlpqeOQ/38ihXZv9Li3wOlprOXzvzfyv75zi//74PN96sZf/dPNu/v2bd9BYU+53eRIQ5tfUV4cOHXJHjx715bkld5xznB+Y5JvHevj6c91cGpmmubacT7x9L//hzTvVKl+Hk71j/OF3TvP4yQglIeMXX9PC+w+1c/O+JirLwn6XJ1lmZs855w6lXJdOoJvZbcD/AcLAXznn/ueS9eXAl4HrgEHgA865CyvtU4FemCZm5jkTGefU5XF+cmGIp84O0jsaxQxu3tfEr1y3nXf/XBsVpQqejToTGedrz3Xzjz/tZmBilrJwiIM76rlxbyOv37aJ/a21bKuv1EnmArOhQDezMHAaeBfQDTwL3O2cO5G0zSeANzjnPm5mdwF3Ouc+sNJ+FejBFIs5ZhdizC7EmJtPfHfMLiwwFp1ndHqOMe9r1Pu6PDZDz8g0PSPT9I6+Oma6sbqMG/Y2cuOeRt7xmha21Vf6+JMVrrmFGE+eHeTJzgGePDvIyz2jJH6tq8rCbKuvpG1TBa11FbTVVdBcW05tRQk15d5XRQnV5SVUl5VQGjZKS0KUhkKUhI2SkBXctH/5bqVAT6cP/Xqg0zl3ztvZw8AdQPKHTdwBfNa7/XXgz8zMXBb6cx55touHfngO4KqZ0t2yd668m/y4pQUm79ItWXvFuhV+svXsf+n+rqz3qmdYZn/rqyPmHHMLMeYWHAuxtb1kFaUhWusq2Lqpkhv3NrK3uYb9rbXsb61hx+YqhUEOlIZDvG1/M2/b3wzERw+djkxwOjLO6cg4PSPTXB6b4UxkgP6JmTW/xiUhoyRsiyEfMiP+ssa/G3jfk+/HX3ezq9eFvBt+vzP8fG9+8p0dvO+NWzO+33QCfRuQ/Kn73cCbl9vGOTdvZqNAIzCQvJGZ3QPcA7Bjx451FdxQXcY1rbVJO71yffLdpS/YleuW3cUVj7vqJb/icUnbrVjH0nWpH3f1+2vt+7clFaf7c5aVhCgNG2XhMKUlRlk45C2Lf5WVhKitKKGuopRNlaXUVZawqbKU8hJ1nQRNbUUp1+1s4LqdDVetW4g5hqdmmYjOMzHjfXm3J2fnmZuPMR9zzC045hdizMXi3+PLYswtxHAu3kCINwpc/L6LN1CS1znid+L3XdLyeCPCVz4//abK7HysRU5HuTjnHgIegniXy3r28a4DrbzrQGtG6xIpFuGQ0VRTTpNGxhSkdIYYXAKSp1vf7i1LuY2ZlQCbiJ8cFRGRHEkn0J8FOsxst5mVAXcBh5dscxj4sHf7V4B/yUb/uYiILG/VLhevT/xe4DHiwxa/6Jw7bmYPAEedc4eBvwa+YmadwBDx0BcRkRxKqw/dOXcEOLJk2f1Jt6PA+zNbmoiIrIUu0xMRKRAKdBGRAqFAFxEpEAp0EZEC4dunLZpZP3BxnQ9vYslVqAES1NpU19qorrULam2FVtdO51xzqhW+BfpGmNnR5T6cxm9BrU11rY3qWrug1lZMdanLRUSkQCjQRUQKRL4G+kN+F7CCoNamutZGda1dUGsrmrrysg9dRESulq8tdBERWUKBLiJSIAIb6Gb2fjM7bmYxMzu0ZN3vmlmnmZ0ys3cv8/jdZvaMt91XvY/+zXSNXzWzY97XBTM7tsx2F8zsJW+7nEykamafNbNLSfW9d5ntbvOOY6eZ3ZeDuj5nZj8zsxfN7BtmVr/Mdjk5Zqv9/GZW7r3Ond77aVe2akl6znYze8LMTni/A59Msc3bzWw06fW9P9W+slTfiq+Nxf2Jd8xeNLNrc1DTNUnH4piZjZnZbyzZJifHzMy+aGZ9ZvZy0rLNZvZdMzvjfb96Oqn4dh/2tjljZh9Otc2KnHOB/AJeC1wD/CtwKGn5AeAFoBzYDZwFwike/whwl3f788B/yXK9fwjcv8y6C0BTjo/fZ4HfWmWbsHf89gBl3nE9kOW6bgVKvNu/D/y+X8csnZ8f+ATwee/2XcBXc/DabQGu9W7XEp+kfWldbwe+lcv3VLqvDfBe4NvEZz28AXgmx/WFgcvEL8DJ+TEDfgG4Fng5adkfAPd5t+9L9b4HNgPnvO8N3u2GtTx3YFvozrmTzrlTKVbdATzsnJtxzp0HOolPZL3I4pNl/iLxCasB/gb45WzV6j3frwJ/n63nyJLFCcCdc7NAYgLwrHHOfcc5N+/dfZr4DFh+Sefnv4P4+wfi76d3WpZnF3bO9TrnfurdHgdOEp+3N1/cAXzZxT0N1JvZlhw+/zuBs8659V6JviHOuR8QnxciWfL7aLk8ejfwXefckHNuGPgucNtanjuwgb6CVJNWL32zNwIjScGRaptMeisQcc6dWWa9A75jZs95E2Xnyr3ev7xfXOZfvHSOZTZ9lHhLLpVcHLN0fv4rJkAHEhOg54TXxXMQeCbF6hvN7AUz+7aZ/VyuamL118bv99VdLN+48uuYtTrner3bl4FUEyNv+LjldJLopczscaAtxapPO+e+met6UkmzxrtZuXV+s3Pukpm1AN81s595f8WzVhvwF8DvEf/l+z3iXUIf3ehzbrSuxDEzs08D88DfLbObrByzfGJmNcA/AL/hnBtbsvqnxLsUJrzzI48CHTkqLbCvjXeu7Hbgd1Os9vOYLXLOOTPLynhxXwPdOXfLOh6WzqTVg8T/zSvxWlWptslIjRafFPvfAtetsI9L3vc+M/sG8X/1N/wLkO7xM7MvAN9KsSqdY5nxuszsI8C/Ad7pvM7DFPvIyjFbYi0ToHdbDidAN7NS4mH+d865f1y6PjngnXNHzOzPzazJOZf1D6FK47XJyvsqTe8Bfuqciyxd4ecxAyJmtsU51+t1P/Wl2OYS8X7+hO3EzyGmLR+7XA4Dd3mjD3YT/wv7k+QNvJB4gviE1RCfwDpbLf5bgJ8557pTrTSzajOrTdwmflLw5VTbZtKSPss7l3nOdCYAz3RdtwG/A9zunJtaZptcHbNAToDu9dH/NXDSOfdHy2zTlujLN7Prif8u5+IPTTqvzWHgQ95olxuA0aTuhmxb9r9lv46ZJ/l9tFwePQbcamYNXhfprd6y9GX7jO8GzhTfSbwPaQaIAI8lrfs08dEJp4D3JC0/Amz1bu8hHvSdwNeA8izV+SXg40uWbQWOJNXxgvd1nHi3Qy6O31eAl4AXvTfTlqW1efffS3wUxdlc1Oa9Hl3AMe/r80vryuUxS/XzAw8Q/4MDUOG9fzq999OeHByjm4l3lb2YdJzeC3w88V4D7vWOzQvETy6/JUfvq5SvzZLaDHjQO6YvkTRKLcu1VRMP6E1Jy3J+zIj/QekF5rwM+xjx8y7fA84AjwObvW0PAX+V9NiPeu+1TuA/rvW5dem/iEiByMcuFxERSUGBLiJSIBToIiIFQoEuIlIgFOgiIgVCgS4iUiAU6CIiBeL/A5HIYL0BI92qAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(temps, 1 - np.tanh(temps) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4c22020",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# Define our weights and biases\n",
    "# Scale them down so values get through the tanh nonlinearity\n",
    "i_weight = np.random.rand(1,5) / 5 - .1\n",
    "h_weight = np.random.rand(5,5) / 5 - .1\n",
    "h_bias = np.random.rand(1,5) / 5 - .1\n",
    "\n",
    "# Tanh pushes values to between -1 and 1, so scale up the output weights\n",
    "o_weight = np.random.rand(5,1) * 50\n",
    "o_bias = np.random.rand(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05e953a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An array to store the output predictions\n",
    "outputs = np.zeros(3)\n",
    "# An array to store hidden states for use in backpropagation\n",
    "hiddens = np.zeros((3, 5))\n",
    "\n",
    "# This will store the previous hidden state, since we'll need it to calculate the current hidden step\n",
    "prev_hidden = None\n",
    "sequence = data[\"tmax\"].tail(3).to_numpy()\n",
    "\n",
    "for i in range(3):\n",
    "    # Get the input sequence at the given position\n",
    "    x = sequence[i].reshape(1,1)\n",
    "\n",
    "    # Multiply input by input weight\n",
    "    xi = x @ i_weight\n",
    "    if prev_hidden is not None:\n",
    "        # Add previous hidden to input\n",
    "        xh = xi + prev_hidden @ h_weight + h_bias\n",
    "    else:\n",
    "        xh = xi\n",
    "\n",
    "    # Apply our activation function\n",
    "    xh = np.tanh(xh)\n",
    "    prev_hidden = xh\n",
    "    hiddens[i,] = xh\n",
    "\n",
    "    # Multiply by the output weight\n",
    "    xo = xh @ o_weight + o_bias\n",
    "    outputs[i] = xo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920c3244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3786437a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([74.31470595, 80.66149404, 77.67852446])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd415c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.56784618,  0.99320288,  0.87557333,  0.53166114, -0.76483255],\n",
       "       [ 0.58366756,  0.99568651,  0.90034879,  0.69338529, -0.84149203],\n",
       "       [ 0.5383306 ,  0.99164251,  0.86287584,  0.66091071, -0.80543591]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiddens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d112d72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(actual, predicted):\n",
    "    return np.mean((actual-predicted)**2)\n",
    "\n",
    "def mse_grad(actual, predicted):\n",
    "    return (predicted - actual)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9496ec90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.31470595, 18.66149404, 12.67852446])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Actual next day temperatures\n",
    "actuals = np.array([70, 62, 65])\n",
    "\n",
    "loss_grad = mse_grad(actuals, outputs)\n",
    "loss_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05cd7097",
   "metadata": {},
   "outputs": [],
   "source": [
    "o_weight_grad, o_bias_grad, h_weight_grad, h_bias_grad, i_weight_grad = [0] * 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6c4e069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the loss wrt the output at the current time step\n",
    "l2_grad = loss_grad[2].reshape(1,1)\n",
    "\n",
    "# Add to the output weight gradient\n",
    "# Multiply the output of the hidden step (hiddens[2]) transposed by the l2 grad\n",
    "# np.newaxis creates a new size 1 axis, effectively transposing the hiddens\n",
    "o_weight_grad += hiddens[2][:,np.newaxis] @ l2_grad\n",
    "# Add to the bias gradient.  Similar to a dense neural network, this is just the mean of the l2_grad.\n",
    "o_bias_grad += np.mean(l2_grad)\n",
    "\n",
    "# Find the gradient wrt the hidden step output\n",
    "h2_grad = l2_grad @ o_weight.T\n",
    "\n",
    "# Derivative of the tanh function\n",
    "tanh_deriv = 1 - hiddens[2,:][np.newaxis,:] ** 2\n",
    "# Multiply each position in the h_grad by the tanh derivative - this \"undoes\" the tanh in the forward pass\n",
    "h2_grad = np.multiply(h2_grad, tanh_deriv)\n",
    "\n",
    "# Now, find how much we need to update the hidden weights.\n",
    "# We take the input to the hidden step (the output of the previous hidden step in the forward pass) @ h2_grad\n",
    "h_weight_grad += hiddens[1,:][:,np.newaxis] @ h2_grad\n",
    "h_bias_grad += np.mean(h2_grad)\n",
    "\n",
    "# This multiples the sequence value at time step 2 by the gradient\n",
    "# We don't need the .T here, but I left it here in case you have a larger input size\n",
    "i_weight_grad += sequence[2].reshape(1,1).T @ h2_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81b93159",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_grad = loss_grad[1].reshape(1,1)\n",
    "\n",
    "o_weight_grad += hiddens[1][:,np.newaxis] @ l1_grad\n",
    "o_bias_grad += np.mean(l1_grad)\n",
    "\n",
    "h1_grad = l1_grad @ o_weight.T\n",
    "\n",
    "# We do have a next sequence position (2), so we need to include that gradient\n",
    "# We multiply the h2 gradient by the weight to pull it back to the current sequence position\n",
    "h1_grad += h2_grad @ h_weight.T\n",
    "\n",
    "# The rest of the operation is the same\n",
    "tanh_deriv = 1 - hiddens[1,:][np.newaxis,:] ** 2\n",
    "h1_grad = np.multiply(h1_grad, tanh_deriv)\n",
    "\n",
    "h_weight_grad += hiddens[1,:][:,np.newaxis] @ h1_grad\n",
    "h_bias_grad += np.mean(h1_grad)\n",
    "\n",
    "i_weight_grad += sequence[1].reshape(1,1).T @ h1_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9dee2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "l0_grad = loss_grad[0].reshape(1,1)\n",
    "\n",
    "o_weight_grad += hiddens[0][:,np.newaxis] @ l0_grad\n",
    "o_bias_grad += np.mean(l0_grad)\n",
    "\n",
    "h0_grad = l0_grad @ o_weight.T\n",
    "\n",
    "h0_grad += h1_grad @ h_weight.T\n",
    "\n",
    "tanh_deriv = 1 - hiddens[0,:][np.newaxis,:] ** 2\n",
    "h0_grad = np.multiply(h0_grad, tanh_deriv)\n",
    "\n",
    "# We don't update the hidden weight, since there was no previous hidden state\n",
    "# We can update the hidden bias if you want\n",
    "\n",
    "i_weight_grad += sequence[0].reshape(1,1).T @ h0_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "50e0e16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[54498.71460476,   926.96931526, 16257.75098388, 66153.99689818,\n",
       "        27292.28884188]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_weight_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13df522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_hidden = None\n",
    "\n",
    "o_weight_grad, o_bias_grad, h_weight_grad, h_bias_grad, i_weight_grad = [0] * 5\n",
    "\n",
    "for i in range(2, -1, -1):\n",
    "    l_grad = loss_grad[i].reshape(1,1)\n",
    "\n",
    "    o_weight_grad += hiddens[i][:,np.newaxis] @ l_grad\n",
    "    o_bias_grad += np.mean(l_grad)\n",
    "\n",
    "    o_grad = l_grad @ o_weight.T\n",
    "\n",
    "    # Only add in the hidden gradient if a next sequence exists\n",
    "    if next_hidden is not None:\n",
    "        h_grad = o_grad + next_hidden @ h_weight.T\n",
    "    else:\n",
    "        h_grad = o_grad\n",
    "\n",
    "    tanh_deriv = 1 - hiddens[i,:][np.newaxis,:] ** 2\n",
    "    h_grad = np.multiply(h_grad, tanh_deriv)\n",
    "\n",
    "    next_hidden = h_grad\n",
    "\n",
    "    # Don't update the hidden weights for the first sequence position\n",
    "    if i > 0:\n",
    "        h_weight_grad += hiddens[i-1,:][:,np.newaxis] @ h_grad\n",
    "        h_bias_grad += np.mean(h_grad)\n",
    "\n",
    "    i_weight_grad += sequence[i].reshape(1,1).T @ h_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3bb6d595",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-6\n",
    "# We'll divide the learning rate by the sequence length, since we were adding together the gradients\n",
    "# This makes training the model more stable\n",
    "lr = lr / 3\n",
    "\n",
    "i_weight -= i_weight_grad * lr\n",
    "h_weight -= h_weight_grad * lr\n",
    "h_bias -= h_bias_grad * lr\n",
    "o_weight -= o_weight_grad * lr\n",
    "o_bias -= o_bias_grad * lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9556b9d9",
   "metadata": {},
   "source": [
    "Full Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "006c2b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import math\n",
    "\n",
    "# Define predictors and target\n",
    "PREDICTORS = [\"tmax\", \"tmin\", \"rain\"]\n",
    "TARGET = \"tmax_tomorrow\"\n",
    "\n",
    "# Scale our data to have mean 0\n",
    "scaler = StandardScaler()\n",
    "data[PREDICTORS] = scaler.fit_transform(data[PREDICTORS])\n",
    "\n",
    "# Split into train, valid, test sets\n",
    "np.random.seed(0)\n",
    "split_data = np.split(data, [int(.7*len(data)), int(.85*len(data))])\n",
    "(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = [[d[PREDICTORS].to_numpy(), d[[TARGET]].to_numpy()] for d in split_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3865d7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(layer_conf):\n",
    "    layers = []\n",
    "    for i in range(1, len(layer_conf)):\n",
    "        np.random.seed(0)\n",
    "        k = 1/math.sqrt(layer_conf[i][\"hidden\"])\n",
    "        i_weight = np.random.rand(layer_conf[i-1][\"units\"], layer_conf[i][\"hidden\"]) * 2 * k - k\n",
    "\n",
    "        h_weight = np.random.rand(layer_conf[i][\"hidden\"], layer_conf[i][\"hidden\"]) * 2 * k - k\n",
    "        h_bias = np.random.rand(1, layer_conf[i][\"hidden\"]) * 2 * k - k\n",
    "\n",
    "        o_weight = np.random.rand(layer_conf[i][\"hidden\"], layer_conf[i][\"output\"]) * 2 * k - k\n",
    "        o_bias = np.random.rand(1, layer_conf[i][\"output\"]) * 2 * k - k\n",
    "\n",
    "        layers.append(\n",
    "            [i_weight, h_weight, h_bias, o_weight, o_bias]\n",
    "        )\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8d65150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, layers):\n",
    "    hiddens = []\n",
    "    outputs = []\n",
    "    for i in range(len(layers)):\n",
    "        i_weight, h_weight, h_bias, o_weight, o_bias = layers[i]\n",
    "        hidden = np.zeros((x.shape[0], i_weight.shape[1]))\n",
    "        output = np.zeros((x.shape[0], o_weight.shape[1]))\n",
    "        for j in range(x.shape[0]):\n",
    "            input_x = x[j,:][np.newaxis,:] @ i_weight\n",
    "            hidden_x = input_x + hidden[max(j-1,0),:][np.newaxis,:] @ h_weight + h_bias\n",
    "            # Activation.  tanh avoids outputs getting larger and larger.\n",
    "            hidden_x = np.tanh(hidden_x)\n",
    "            # Store hidden for use in backprop\n",
    "            hidden[j,:] = hidden_x\n",
    "\n",
    "            # Output layer\n",
    "            output_x = hidden_x @ o_weight + o_bias\n",
    "            output[j,:] = output_x\n",
    "        hiddens.append(hidden)\n",
    "        outputs.append(output)\n",
    "    return hiddens, outputs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6701a22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(layers, x, lr, grad, hiddens):\n",
    "    for i in range(len(layers)):\n",
    "        i_weight, h_weight, h_bias, o_weight, o_bias = layers[i]\n",
    "        hidden = hiddens[i]\n",
    "        next_h_grad = None\n",
    "        i_weight_grad, h_weight_grad, h_bias_grad, o_weight_grad, o_bias_grad = [0] * 5\n",
    "\n",
    "        for j in range(x.shape[0] - 1, -1, -1):\n",
    "            # Add newaxis in the first dimension\n",
    "            out_grad = grad[j,:][np.newaxis, :]\n",
    "\n",
    "            # Output updates\n",
    "            # np.newaxis creates a size 1 axis, in this case transposing matrix\n",
    "            o_weight_grad += hidden[j,:][:, np.newaxis] @ out_grad\n",
    "            o_bias_grad += out_grad\n",
    "\n",
    "            # Propagate gradient to hidden unit\n",
    "            h_grad = out_grad @ o_weight.T\n",
    "\n",
    "            if j < x.shape[0] - 1:\n",
    "                # Then we multiply the gradient by the hidden weights to pull gradient from next hidden state to current hidden state\n",
    "                hh_grad = next_h_grad @ h_weight.T\n",
    "                # Add the gradients together to combine output contribution and hidden contribution\n",
    "                h_grad += hh_grad\n",
    "\n",
    "            # Pull the gradient across the current hidden nonlinearity\n",
    "            # derivative of tanh is 1 - tanh(x) ** 2\n",
    "            # So we take the output of tanh (next hidden state), and plug in\n",
    "            tanh_deriv = 1 - hidden[j][np.newaxis,:] ** 2\n",
    "\n",
    "            # next_h_grad @ np.diag(tanh_deriv_next) multiplies each element of next_h_grad by the deriv\n",
    "            # Effect is to pull value across nonlinearity\n",
    "            h_grad = np.multiply(h_grad, tanh_deriv)\n",
    "\n",
    "            # Store to compute h grad for previous sequence position\n",
    "            next_h_grad = h_grad.copy()\n",
    "\n",
    "            # If we're not at the very beginning\n",
    "            if j > 0:\n",
    "                # Multiply input from previous layer by post-nonlinearity grad at current layer\n",
    "                h_weight_grad += hidden[j-1][:, np.newaxis] @ h_grad\n",
    "                h_bias_grad += h_grad\n",
    "\n",
    "            i_weight_grad += x[j,:][:,np.newaxis] @ h_grad\n",
    "\n",
    "        # Normalize lr by number of sequence elements\n",
    "        lr = lr / x.shape[0]\n",
    "        i_weight -= i_weight_grad * lr\n",
    "        h_weight -= h_weight_grad * lr\n",
    "        h_bias -= h_bias_grad * lr\n",
    "        o_weight -= o_weight_grad * lr\n",
    "        o_bias -= o_bias_grad * lr\n",
    "        layers[i] = [i_weight, h_weight, h_bias, o_weight, o_bias]\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8d1d2c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 train loss 3122.594400144508 valid loss 2171.318686210202\n",
      "Epoch: 50 train loss 30.59319327531357 valid loss 30.56827174010336\n",
      "Epoch: 100 train loss 25.263986813543685 valid loss 24.43551751035559\n",
      "Epoch: 150 train loss 22.95676242953127 valid loss 22.17701097197682\n",
      "Epoch: 200 train loss 22.30677432770419 valid loss 21.557992202834146\n"
     ]
    }
   ],
   "source": [
    "epochs = 250\n",
    "lr = 1e-5\n",
    "\n",
    "layer_conf = [\n",
    "    {\"type\":\"input\", \"units\": 3},\n",
    "    {\"type\": \"rnn\", \"hidden\": 4, \"output\": 1}\n",
    "]\n",
    "layers = init_params(layer_conf)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    sequence_len = 7\n",
    "    epoch_loss = 0\n",
    "    for j in range(train_x.shape[0] - sequence_len):\n",
    "        seq_x = train_x[j:(j+sequence_len),]\n",
    "        seq_y = train_y[j:(j+sequence_len),]\n",
    "        hiddens, outputs = forward(seq_x, layers)\n",
    "        grad = mse_grad(seq_y, outputs)\n",
    "        params = backward(layers, seq_x, lr, grad, hiddens)\n",
    "        epoch_loss += mse(seq_y, outputs)\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        sequence_len = 7\n",
    "        valid_loss = 0\n",
    "        for j in range(valid_x.shape[0] - sequence_len):\n",
    "            seq_x = valid_x[j:(j+sequence_len),]\n",
    "            seq_y = valid_y[j:(j+sequence_len),]\n",
    "            _, outputs = forward(seq_x, layers)\n",
    "            valid_loss += mse(seq_y, outputs)\n",
    "\n",
    "        print(f\"Epoch: {epoch} train loss {epoch_loss / len(train_x)} valid loss {valid_loss / len(valid_x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a19a11b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
